#!/usr/bin/env python3
"""
å¼‚æ­¥ä¸‹è½½å™¨ - å®æˆ˜é¡¹ç›®1
å¯ä»¥å¹¶å‘ä¸‹è½½å¤šä¸ªURLå†…å®¹
è¿è¡Œæ–¹æ³•ï¼špython async_downloader.py
éœ€è¦å®‰è£…ï¼špip install aiohttp
"""

import asyncio
import aiohttp
import time
from typing import List, Dict
import os

class AsyncDownloader:
    """å¼‚æ­¥ä¸‹è½½å™¨ç±»"""
    
    def __init__(self, max_concurrent: int = 5, timeout: int = 10):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.session = None
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=10)
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': 'AsyncDownloader/1.0'}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def download_single(self, url: str) -> Dict[str, any]:
        """ä¸‹è½½å•ä¸ªURL"""
        try:
            async with self.session.get(url) as response:
                content = await response.text()
                content_length = len(content)
                
                print(f"âœ… {url} - çŠ¶æ€ç : {response.status}, å¤§å°: {content_length:,}å­—ç¬¦")
                
                return {
                    'url': url,
                    'status_code': response.status,
                    'success': True,
                    'content_length': content_length,
                    'content_preview': content[:200] + '...' if len(content) > 200 else content,
                    'headers': dict(response.headers)
                }
                
        except asyncio.TimeoutError:
            print(f"â° {url} - è¶…æ—¶")
            return {
                'url': url,
                'success': False,
                'error': 'timeout',
                'error_message': 'è¯·æ±‚è¶…æ—¶'
            }
        except aiohttp.ClientError as e:
            print(f"âŒ {url} - ç½‘ç»œé”™è¯¯: {e}")
            return {
                'url': url,
                'success': False,
                'error': 'network_error',
                'error_message': str(e)
            }
        except Exception as e:
            print(f"ğŸ’¥ {url} - æ„å¤–é”™è¯¯: {e}")
            return {
                'url': url,
                'success': False,
                'error': 'unknown_error',
                'error_message': str(e)
            }
    
    async def download_multiple(self, urls: List[str]) -> List[Dict[str, any]]:
        """å¹¶å‘ä¸‹è½½å¤šä¸ªURL"""
        if not self.session:
            raise RuntimeError("è¯·ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def download_with_semaphore(url: str):
            async with semaphore:
                return await self.download_single(url)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [download_with_semaphore(url) for url in urls]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                processed_results.append({
                    'success': False,
                    'error': 'exception',
                    'error_message': str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def download_with_progress(self, urls: List[str]) -> Dict[str, any]:
        """å¸¦è¿›åº¦æ˜¾ç¤ºçš„ä¸‹è½½"""
        total_urls = len(urls)
        completed = 0
        failed = 0
        
        print(f"\nğŸŒ å¼€å§‹ä¸‹è½½ {total_urls} ä¸ªURL")
        print(f"æœ€å¤§å¹¶å‘æ•°: {self.max_concurrent}")
        print("-" * 50)
        
        results = await self.download_multiple(urls)
        
        # ç»Ÿè®¡ç»“æœ
        successful_results = [r for r in results if r['success']]
        failed_results = [r for r in results if not r['success']]
        
        total_size = sum(r.get('content_length', 0) for r in successful_results)
        
        return {
            'total_urls': total_urls,
            'successful': len(successful_results),
            'failed': len(failed_results),
            'total_size': total_size,
            'results': results,
            'success_rate': len(successful_results) / total_urls * 100
        }

class FileDownloader(AsyncDownloader):
    """æ–‡ä»¶ä¸‹è½½å™¨ï¼Œæ”¯æŒä¿å­˜åˆ°æœ¬åœ°"""
    
    async def download_file(self, url: str, save_path: str) -> Dict[str, any]:
        """ä¸‹è½½æ–‡ä»¶å¹¶ä¿å­˜åˆ°æœ¬åœ°"""
        try:
            async with self.session.get(url) as response:
                if response.status != 200:
                    return {
                        'url': url,
                        'success': False,
                        'error': f'HTTP {response.status}'
                    }
                
                content = await response.read()
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(save_path), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(save_path, 'wb') as f:
                    f.write(content)
                
                file_size = len(content)
                print(f"ğŸ’¾ å·²ä¿å­˜: {save_path} ({file_size:,}å­—èŠ‚)")
                
                return {
                    'url': url,
                    'save_path': save_path,
                    'file_size': file_size,
                    'success': True
                }
                
        except Exception as e:
            return {
                'url': url,
                'success': False,
                'error': str(e)
            }

# æµ‹è¯•URLåˆ—è¡¨
TEST_URLS = [
    'https://httpbin.org/delay/1',
    'https://jsonplaceholder.typicode.com/posts/1',
    'https://httpbin.org/delay/2',
    'https://jsonplaceholder.typicode.com/posts/2',
    'https://httpbin.org/user-agent',
    'https://jsonplaceholder.typicode.com/posts/3',
    'https://httpbin.org/headers',
    'https://jsonplaceholder.typicode.com/posts/4',
]

async def demo_basic_download():
    """åŸºç¡€ä¸‹è½½æ¼”ç¤º"""
    print("ğŸ¯ åŸºç¡€ä¸‹è½½æ¼”ç¤º")
    
    async with AsyncDownloader(max_concurrent=4) as downloader:
        start_time = time.time()
        
        results = await downloader.download_with_progress(TEST_URLS[:5])
        
        elapsed = time.time() - start_time
        
        print("\n" + "="*60)
        print("ğŸ“Š ä¸‹è½½ç»Ÿè®¡")
        print(f"æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        print(f"æˆåŠŸ: {results['successful']}/{results['total_urls']}")
        print(f"å¤±è´¥: {results['failed']}/{results['total_urls']}")
        print(f"æˆåŠŸç‡: {results['success_rate']:.1f}%")
        print(f"æ€»ä¸‹è½½å¤§å°: {results['total_size']:,}å­—ç¬¦")
        
        if results['failed'] > 0:
            print("\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
            for result in results['results']:
                if not result['success']:
                    print(f"  {result['url']}: {result['error_message']}")

async def demo_file_download():
    """æ–‡ä»¶ä¸‹è½½æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸ—‚ï¸ æ–‡ä»¶ä¸‹è½½æ¼”ç¤º")
    
    file_urls = [
        ('https://httpbin.org/robots.txt', 'downloads/robots.txt'),
        ('https://jsonplaceholder.typicode.com/posts', 'downloads/posts.json'),
    ]
    
    async with FileDownloader(max_concurrent=2) as downloader:
        start_time = time.time()
        
        tasks = [
            downloader.download_file(url, path)
            for url, path in file_urls
        ]
        
        results = await asyncio.gather(*tasks)
        
        elapsed = time.time() - start_time
        
        print(f"\nğŸ“Š æ–‡ä»¶ä¸‹è½½ç»Ÿè®¡")
        print(f"æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        
        for result in results:
            if result['success']:
                print(f"âœ… {result['url']} â†’ {result['save_path']}")
            else:
                print(f"âŒ {result['url']}: {result['error']}")

async def demo_error_handling():
    """é”™è¯¯å¤„ç†æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸ›¡ï¸ é”™è¯¯å¤„ç†æ¼”ç¤º")
    
    # åŒ…å«ä¸€äº›ä¼šå¤±è´¥çš„URL
    test_urls = [
        'https://httpbin.org/status/200',  # æˆåŠŸ
        'https://httpbin.org/status/404',  # 404é”™è¯¯
        'https://invalid-url-that-does-not-exist.com',  # åŸŸåé”™è¯¯
        'https://httpbin.org/delay/10',  # è¶…æ—¶æµ‹è¯•
        'https://httpbin.org/status/500',  # æœåŠ¡å™¨é”™è¯¯
    ]
    
    async with AsyncDownloader(max_concurrent=3, timeout=5) as downloader:
        results = await downloader.download_multiple(test_urls)
        
        print("\nğŸ“Š é”™è¯¯å¤„ç†ç»“æœ:")
        for result in results:
            if result['success']:
                print(f"âœ… {result['url']}: æˆåŠŸ ({result['status_code']})")
            else:
                print(f"âŒ {result['url']}: {result['error_message']}")

async def demo_custom_urls():
    """è‡ªå®šä¹‰URLä¸‹è½½æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸŒ è‡ªå®šä¹‰URLä¸‹è½½")
    
    # ç”¨æˆ·å¯ä»¥ä¿®æ”¹è¿™äº›URL
    custom_urls = [
        'https://api.github.com/users/octocat',
        'https://api.github.com/repos/microsoft/vscode',
        'https://httpbin.org/json',
        'https://httpbin.org/xml',
    ]
    
    async with AsyncDownloader(max_concurrent=2) as downloader:
        results = await downloader.download_with_progress(custom_urls)
        
        # æ˜¾ç¤ºæˆåŠŸçš„å†…å®¹é¢„è§ˆ
        for result in results['results']:
            if result['success'] and 'content_preview' in result:
                print(f"\nğŸ“„ {result['url']} å†…å®¹é¢„è§ˆ:")
                print(result['content_preview'])
                print("-" * 40)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼‚æ­¥ä¸‹è½½å™¨æ¼”ç¤ºå¼€å§‹")
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    os.makedirs('downloads', exist_ok=True)
    
    # è¿è¡Œå„ç§æ¼”ç¤º
    await demo_basic_download()
    await demo_file_download()
    await demo_error_handling()
    await demo_custom_urls()
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ“ æ£€æŸ¥ downloads/ ç›®å½•æŸ¥çœ‹ä¸‹è½½çš„æ–‡ä»¶")

if __name__ == "__main__":
    asyncio.run(main())